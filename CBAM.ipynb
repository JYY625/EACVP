{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,Conv1D\n",
    "from tensorflow.keras.layers import AveragePooling2D, MaxPooling2D, Dropout, AveragePooling1D, MaxPooling1D\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('anti-bacterial_test.xlsx')\n",
    "y_test = dataset['label']\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the dataset \n",
    "X_train_data_name = 'anti-bacterial_esm2_train.csv'\n",
    "X_train_data = pd.read_csv(X_train_data_name,header=0, index_col = 0,delimiter=',')\n",
    "\n",
    "X_test_data_name = 'anti-bacterial_esm2_test.csv'\n",
    "X_test_data = pd.read_csv(X_test_data_name,header=0, index_col = 0,delimiter=',')\n",
    "\n",
    "X_train = np.array(X_train_data)\n",
    "X_test = np.array(X_test_data)\n",
    "\n",
    "\n",
    "# normalize the X data range\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, Activation, multiply, add, GlobalAveragePooling1D, Flatten,Reshape\n",
    "from tensorflow.keras.models import Sequential,Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_attention(input_feature, reduction_ratio=8): # 定义通道注意力\n",
    "    channel = input_feature.shape[-1]\n",
    "    avg_pool = GlobalAveragePooling1D()(input_feature)\n",
    "    avg_pool = Reshape((1, 1, channel))(avg_pool)\n",
    "    avg_pool = Conv1D(channel//reduction_ratio, (3), padding='same', activation='relu')(avg_pool)\n",
    "    avg_pool = Conv1D(channel, (1), padding='same')(avg_pool)\n",
    "#     max_pool = tf.keras.layers.GlobalMaxPooling1D()(input_feature)\n",
    "    max_pool = Reshape((1, 1, channel))(avg_pool)\n",
    "    max_pool = Conv1D(channel//reduction_ratio, (3), padding='same', activation='relu')(max_pool)\n",
    "    max_pool = Conv1D(channel, (1), padding='same')(max_pool)\n",
    "    scale = add([avg_pool, max_pool])\n",
    "    scale = Activation('sigmoid')(scale)\n",
    "    return multiply([input_feature, scale])\n",
    "\n",
    "def spatial_attention(input_feature): # 定义空间注意力 kernel_size = 7\n",
    "    avg_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x, axis=3, keepdims=True))(input_feature)\n",
    "    max_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.max(x, axis=3, keepdims=True))(input_feature)\n",
    "    concat = tf.keras.layers.Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    concat = Conv1D(1, (3), padding='same', activation='sigmoid')(concat)\n",
    "    return multiply([input_feature, concat])\n",
    "\n",
    "def cbam_block(cbam_feature): # 定义CBAM注意力块\n",
    "    cbam_feature = channel_attention(cbam_feature)\n",
    "    cbam_feature = spatial_attention(cbam_feature)\n",
    "    return cbam_feature\n",
    "\n",
    "def build_model(X_train, y_train, X_test, y_test): # 手写数字分类任务简单的CNN模型\n",
    "    input = tf.keras.layers.Input(shape=(320,1))\n",
    "    conv1 = Conv1D(32, (3), strides=(1), padding='same', activation='relu')(input) #(B,320,32)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "#     conv1 = MaxPooling1D((2), name='MaxPool1',padding=\"same\")(conv1)\n",
    "    conv2 = Conv1D(64, (3), strides=(1), padding='same', activation='relu')(conv1)  #(B,320,64)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "#     conv2 = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(conv2)\n",
    "    conv3 = Conv1D(128, (3), strides=(1), padding='same', activation='relu')(conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = cbam_block(conv3)  #(B,1,320,128)# 加入CBAM注意力机制\n",
    "    conv3 = tf.squeeze(conv3,1) #(B,320,128)\n",
    "    flatten = Flatten()(conv3) #(B,128)\n",
    "    x = tf.keras.layers.Dense(units=2, activation='softmax')(flatten)\n",
    "    model = Model(inputs = input,outputs = x,name='Predict')\n",
    "  # define SGD optimizer\n",
    "#     momentum = 0.9\n",
    "#     sgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False)\n",
    "    adam = Adam(learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False)\n",
    "  # compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer=adam, metrics=['accuracy'])\n",
    "  # learning deccay setting\n",
    "    import math\n",
    "    def step_decay(epoch): # gradually decrease the learning rate\n",
    "        initial_lrate=0.01\n",
    "        drop=0.6\n",
    "        epochs_drop = 3.0\n",
    "        lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
    "              math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
    "        return lrate\n",
    "    lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "  # early stop setting\n",
    "    early_stop = EarlyStopping(monitor='val_accuracy', patience = 50,restore_best_weights = True)\n",
    "\n",
    "  # summary the callbacks_list\n",
    "    callbacks_list = [ lrate , early_stop]\n",
    "\n",
    "    model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                            epochs=100,callbacks=callbacks_list,batch_size = 16, verbose=1)\n",
    "    return model, model_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 8s 44ms/step - loss: 0.8495 - accuracy: 0.8993 - val_loss: 0.8303 - val_accuracy: 0.5438 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 6s 41ms/step - loss: 0.1183 - accuracy: 0.9539 - val_loss: 0.7351 - val_accuracy: 0.5492 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 0.0814 - accuracy: 0.9691 - val_loss: 0.3411 - val_accuracy: 0.8283 - lr: 0.0060\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.0670 - accuracy: 0.9740 - val_loss: 0.1691 - val_accuracy: 0.9249 - lr: 0.0060\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.0649 - accuracy: 0.9740 - val_loss: 0.0954 - val_accuracy: 0.9678 - lr: 0.0060\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.0419 - accuracy: 0.9839 - val_loss: 0.0994 - val_accuracy: 0.9571 - lr: 0.0036\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 0.0423 - accuracy: 0.9821 - val_loss: 0.1009 - val_accuracy: 0.9642 - lr: 0.0036\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.0321 - accuracy: 0.9884 - val_loss: 0.1177 - val_accuracy: 0.9589 - lr: 0.0036\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0942 - val_accuracy: 0.9624 - lr: 0.0022\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.0913 - val_accuracy: 0.9660 - lr: 0.0022\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 0.0187 - accuracy: 0.9946 - val_loss: 0.0936 - val_accuracy: 0.9678 - lr: 0.0022\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.0115 - accuracy: 0.9978 - val_loss: 0.0802 - val_accuracy: 0.9642 - lr: 0.0013\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.1104 - val_accuracy: 0.9660 - lr: 0.0013\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 8s 54ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.0848 - val_accuracy: 0.9696 - lr: 0.0013\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 8s 59ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 0.1107 - val_accuracy: 0.9660 - lr: 7.7760e-04\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 0.0946 - val_accuracy: 0.9660 - lr: 7.7760e-04\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0054 - accuracy: 0.9996 - val_loss: 0.0940 - val_accuracy: 0.9660 - lr: 7.7760e-04\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9678 - lr: 4.6656e-04\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 8s 59ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9606 - lr: 4.6656e-04\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 8s 58ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9660 - lr: 4.6656e-04\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9678 - lr: 2.7994e-04\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 8s 57ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9678 - lr: 2.7994e-04\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9660 - lr: 2.7994e-04\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9678 - lr: 1.6796e-04\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 8s 58ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9660 - lr: 1.6796e-04\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 8s 59ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9660 - lr: 1.6796e-04\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 8s 56ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9660 - lr: 1.0078e-04\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 9s 62ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9660 - lr: 1.0078e-04\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 9s 64ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9660 - lr: 1.0078e-04\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 8s 57ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9660 - lr: 6.0466e-05\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 9s 61ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9660 - lr: 6.0466e-05\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 9s 62ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9660 - lr: 6.0466e-05\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9660 - lr: 3.6280e-05\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9660 - lr: 3.6280e-05\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9660 - lr: 3.6280e-05\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9660 - lr: 2.1768e-05\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9660 - lr: 2.1768e-05\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9660 - lr: 2.1768e-05\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9660 - lr: 1.3061e-05\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 0.9660 - lr: 1.3061e-05\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9660 - lr: 1.3061e-05\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9660 - lr: 7.8364e-06\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 0.9660 - lr: 7.8364e-06\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9660 - lr: 7.8364e-06\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9660 - lr: 4.7018e-06\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9660 - lr: 4.7018e-06\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1081 - val_accuracy: 0.9660 - lr: 4.7018e-06\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9660 - lr: 2.8211e-06\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9642 - lr: 2.8211e-06\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 8s 54ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1081 - val_accuracy: 0.9642 - lr: 2.8211e-06\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 8s 56ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9642 - lr: 1.6927e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9660 - lr: 1.6927e-06\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9642 - lr: 1.6927e-06\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9660 - lr: 1.0156e-06\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9660 - lr: 1.0156e-06\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9642 - lr: 1.0156e-06\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9660 - lr: 6.0936e-07\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9660 - lr: 6.0936e-07\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9660 - lr: 6.0936e-07\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9642 - lr: 3.6562e-07\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 8s 61ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9642 - lr: 3.6562e-07\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 9s 62ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9642 - lr: 3.6562e-07\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9642 - lr: 2.1937e-07\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9642 - lr: 2.1937e-07\n",
      "559/559 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 10s 53ms/step - loss: 0.2334 - accuracy: 0.9029 - val_loss: 0.6837 - val_accuracy: 0.5420 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.1270 - accuracy: 0.9485 - val_loss: 0.1705 - val_accuracy: 0.9338 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 0.0949 - accuracy: 0.9673 - val_loss: 0.2957 - val_accuracy: 0.9177 - lr: 0.0060\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 0.0561 - accuracy: 0.9812 - val_loss: 0.1424 - val_accuracy: 0.9481 - lr: 0.0060\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 0.0452 - accuracy: 0.9848 - val_loss: 0.1294 - val_accuracy: 0.9553 - lr: 0.0060\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.0234 - accuracy: 0.9911 - val_loss: 0.1175 - val_accuracy: 0.9624 - lr: 0.0036\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.0193 - accuracy: 0.9919 - val_loss: 0.1629 - val_accuracy: 0.9553 - lr: 0.0036\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 0.0371 - accuracy: 0.9866 - val_loss: 0.1242 - val_accuracy: 0.9642 - lr: 0.0036\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1358 - val_accuracy: 0.9589 - lr: 0.0022\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9642 - lr: 0.0022\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 8.2013e-04 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9660 - lr: 0.0022\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 5.5137e-04 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9660 - lr: 0.0013\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 5.4212e-04 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9660 - lr: 0.0013\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 3.3018e-04 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9660 - lr: 0.0013\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 2.8733e-04 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 0.9660 - lr: 7.7760e-04\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 2.5153e-04 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9660 - lr: 7.7760e-04\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 2.6018e-04 - accuracy: 1.0000 - val_loss: 0.1543 - val_accuracy: 0.9642 - lr: 7.7760e-04\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 2.0216e-04 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9660 - lr: 4.6656e-04\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 2.0949e-04 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9660 - lr: 4.6656e-04\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 2.1699e-04 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9660 - lr: 4.6656e-04\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 1.8089e-04 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9660 - lr: 2.7994e-04\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 1.6871e-04 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9660 - lr: 2.7994e-04\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 1.6390e-04 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9660 - lr: 2.7994e-04\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.5482e-04 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9660 - lr: 1.6796e-04\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.6527e-04 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9660 - lr: 1.6796e-04\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 8s 57ms/step - loss: 1.4273e-04 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9660 - lr: 1.6796e-04\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 1.3449e-04 - accuracy: 1.0000 - val_loss: 0.1626 - val_accuracy: 0.9660 - lr: 1.0078e-04\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 1.4225e-04 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9660 - lr: 1.0078e-04\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 1.2680e-04 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9660 - lr: 1.0078e-04\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 1.6682e-04 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9660 - lr: 6.0466e-05\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 1.3046e-04 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9660 - lr: 6.0466e-05\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 1.2258e-04 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9660 - lr: 6.0466e-05\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 1.3093e-04 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9660 - lr: 3.6280e-05\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 1.5998e-04 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9660 - lr: 3.6280e-05\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 1.2134e-04 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9660 - lr: 3.6280e-05\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 1.1175e-04 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9660 - lr: 2.1768e-05\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 1.1833e-04 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9660 - lr: 2.1768e-05\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 1.1384e-04 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9660 - lr: 2.1768e-05\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 1.3005e-04 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9660 - lr: 1.3061e-05\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 1.1433e-04 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9660 - lr: 1.3061e-05\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 1.5540e-04 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9660 - lr: 1.3061e-05\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 1.2169e-04 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9660 - lr: 7.8364e-06\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 1.2607e-04 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9660 - lr: 7.8364e-06\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.2314e-04 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9660 - lr: 7.8364e-06\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 1.1950e-04 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9660 - lr: 4.7018e-06\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 1.1840e-04 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9660 - lr: 4.7018e-06\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 1.1490e-04 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9660 - lr: 4.7018e-06\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 1.0103e-04 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9660 - lr: 2.8211e-06\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 1.2122e-04 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9660 - lr: 2.8211e-06\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 1.1833e-04 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9660 - lr: 2.8211e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 1.1451e-04 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9660 - lr: 1.6927e-06\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 1.3009e-04 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9660 - lr: 1.6927e-06\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 1.1286e-04 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9660 - lr: 1.6927e-06\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 1.0560e-04 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9660 - lr: 1.0156e-06\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 1.0658e-04 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9660 - lr: 1.0156e-06\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 1.1265e-04 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9660 - lr: 1.0156e-06\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 1.2020e-04 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9660 - lr: 6.0936e-07\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 1.1058e-04 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9660 - lr: 6.0936e-07\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 1.1124e-04 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9660 - lr: 6.0936e-07\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 1.1701e-04 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9660 - lr: 3.6562e-07\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 1.0814e-04 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9660 - lr: 3.6562e-07\n",
      "559/559 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 8s 46ms/step - loss: 0.2973 - accuracy: 0.9172 - val_loss: 1.5510 - val_accuracy: 0.5098 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.1439 - accuracy: 0.9490 - val_loss: 0.7165 - val_accuracy: 0.5242 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.0900 - accuracy: 0.9633 - val_loss: 0.6871 - val_accuracy: 0.7281 - lr: 0.0060\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.0628 - accuracy: 0.9785 - val_loss: 0.2008 - val_accuracy: 0.9320 - lr: 0.0060\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.0585 - accuracy: 0.9794 - val_loss: 0.1693 - val_accuracy: 0.9410 - lr: 0.0060\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.0209 - accuracy: 0.9924 - val_loss: 0.1661 - val_accuracy: 0.9481 - lr: 0.0036\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.1858 - val_accuracy: 0.9517 - lr: 0.0036\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0124 - accuracy: 0.9973 - val_loss: 0.2316 - val_accuracy: 0.9499 - lr: 0.0036\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1819 - val_accuracy: 0.9553 - lr: 0.0022\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 7.8051e-04 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9571 - lr: 0.0022\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 3.5422e-04 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9606 - lr: 0.0022\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 2.6034e-04 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9589 - lr: 0.0013\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 2.1341e-04 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9606 - lr: 0.0013\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 1.9117e-04 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9589 - lr: 0.0013\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 1.4654e-04 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9606 - lr: 7.7760e-04\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 1.5388e-04 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9606 - lr: 7.7760e-04\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 1.3144e-04 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9606 - lr: 7.7760e-04\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 1.1897e-04 - accuracy: 1.0000 - val_loss: 0.2210 - val_accuracy: 0.9606 - lr: 4.6656e-04\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 1.1873e-04 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9606 - lr: 4.6656e-04\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 1.1068e-04 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9606 - lr: 4.6656e-04\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 9.8155e-05 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9606 - lr: 2.7994e-04\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 9.1213e-05 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9606 - lr: 2.7994e-04\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 9.6491e-05 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9606 - lr: 2.7994e-04\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 1.2665e-04 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9606 - lr: 1.6796e-04\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 8.5400e-05 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9606 - lr: 1.6796e-04\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 9.0302e-05 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9606 - lr: 1.6796e-04\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 8.7967e-05 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9606 - lr: 1.0078e-04\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 8.8111e-05 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9606 - lr: 1.0078e-04\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 8.7105e-05 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9606 - lr: 1.0078e-04\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 8.6237e-05 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9606 - lr: 6.0466e-05\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 8.4950e-05 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9606 - lr: 6.0466e-05\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 7.5196e-05 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9606 - lr: 6.0466e-05\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 8.1747e-05 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9606 - lr: 3.6280e-05\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 8.5261e-05 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.9606 - lr: 3.6280e-05\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 7.1636e-05 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9606 - lr: 3.6280e-05\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 7.4825e-05 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9606 - lr: 2.1768e-05\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 8.6621e-05 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9606 - lr: 2.1768e-05\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 7.3954e-05 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9606 - lr: 2.1768e-05\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 7.9957e-05 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9606 - lr: 1.3061e-05\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 7.3944e-05 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9606 - lr: 1.3061e-05\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 7.0883e-05 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9606 - lr: 1.3061e-05\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 7.5458e-05 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9606 - lr: 7.8364e-06\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 8.2744e-05 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9606 - lr: 7.8364e-06\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 8.3615e-05 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9606 - lr: 7.8364e-06\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 7.3749e-05 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9606 - lr: 4.7018e-06\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 7.3189e-05 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9606 - lr: 4.7018e-06\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 7.3642e-05 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9606 - lr: 4.7018e-06\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 7.4809e-05 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9606 - lr: 2.8211e-06\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 7.4065e-05 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9606 - lr: 2.8211e-06\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 7.7219e-05 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9606 - lr: 2.8211e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 8.5906e-05 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9606 - lr: 1.6927e-06\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 7.1559e-05 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9606 - lr: 1.6927e-06\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 8.0083e-05 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9606 - lr: 1.6927e-06\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 7.5040e-05 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9606 - lr: 1.0156e-06\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 7.7266e-05 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9606 - lr: 1.0156e-06\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 8.1831e-05 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9606 - lr: 1.0156e-06\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 6.9387e-05 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9606 - lr: 6.0936e-07\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 7.2168e-05 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9606 - lr: 6.0936e-07\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 6.6030e-05 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9606 - lr: 6.0936e-07\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 7.2777e-05 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9606 - lr: 3.6562e-07\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 7.7443e-05 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9606 - lr: 3.6562e-07\n",
      "559/559 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 9s 50ms/step - loss: 0.4252 - accuracy: 0.9141 - val_loss: 1.0513 - val_accuracy: 0.5349 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.1024 - accuracy: 0.9633 - val_loss: 0.3776 - val_accuracy: 0.8909 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.0546 - accuracy: 0.9799 - val_loss: 0.3144 - val_accuracy: 0.8515 - lr: 0.0060\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.0445 - accuracy: 0.9834 - val_loss: 0.1434 - val_accuracy: 0.9499 - lr: 0.0060\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 0.0339 - accuracy: 0.9884 - val_loss: 0.1638 - val_accuracy: 0.9410 - lr: 0.0060\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.0207 - accuracy: 0.9924 - val_loss: 0.1116 - val_accuracy: 0.9660 - lr: 0.0036\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 0.0157 - accuracy: 0.9960 - val_loss: 0.1262 - val_accuracy: 0.9589 - lr: 0.0036\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.1169 - val_accuracy: 0.9678 - lr: 0.0036\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1427 - val_accuracy: 0.9535 - lr: 0.0022\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9589 - lr: 0.0022\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9571 - lr: 0.0022\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9571 - lr: 0.0013\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9553 - lr: 0.0013\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9571 - lr: 0.0013\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 8.7948e-04 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9571 - lr: 7.7760e-04\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 7.2985e-04 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9553 - lr: 7.7760e-04\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 6.8811e-04 - accuracy: 1.0000 - val_loss: 0.1627 - val_accuracy: 0.9553 - lr: 7.7760e-04\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 7.2237e-04 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9571 - lr: 4.6656e-04\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 5.9750e-04 - accuracy: 1.0000 - val_loss: 0.1671 - val_accuracy: 0.9571 - lr: 4.6656e-04\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 6.4590e-04 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9553 - lr: 4.6656e-04\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 5.5387e-04 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9571 - lr: 2.7994e-04\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 5.1727e-04 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9571 - lr: 2.7994e-04\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 5.3732e-04 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9571 - lr: 2.7994e-04\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 5.4800e-04 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9553 - lr: 1.6796e-04\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 5.1669e-04 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9571 - lr: 1.6796e-04\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 4.9981e-04 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9571 - lr: 1.6796e-04\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 4.6489e-04 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9553 - lr: 1.0078e-04\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 8s 54ms/step - loss: 5.0723e-04 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9553 - lr: 1.0078e-04\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 4.4193e-04 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9553 - lr: 1.0078e-04\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 4.7005e-04 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9553 - lr: 6.0466e-05\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 4.3280e-04 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9553 - lr: 6.0466e-05\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 4.1549e-04 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9553 - lr: 6.0466e-05\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 4.1650e-04 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9553 - lr: 3.6280e-05\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 4.1086e-04 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 0.9553 - lr: 3.6280e-05\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 4.1239e-04 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9553 - lr: 3.6280e-05\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 4.6657e-04 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.9553 - lr: 2.1768e-05\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 4.7130e-04 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9553 - lr: 2.1768e-05\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 4.2537e-04 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.9553 - lr: 2.1768e-05\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 4.2882e-04 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9553 - lr: 1.3061e-05\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 4.3170e-04 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9553 - lr: 1.3061e-05\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 4.0557e-04 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9553 - lr: 1.3061e-05\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 4.5518e-04 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9553 - lr: 7.8364e-06\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 4.4908e-04 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9553 - lr: 7.8364e-06\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 4.3823e-04 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9553 - lr: 7.8364e-06\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 4.5469e-04 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9553 - lr: 4.7018e-06\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 3.7839e-04 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9553 - lr: 4.7018e-06\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 4.4890e-04 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9553 - lr: 4.7018e-06\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 4.0296e-04 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9553 - lr: 2.8211e-06\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 3.7573e-04 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9553 - lr: 2.8211e-06\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 3.9833e-04 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9553 - lr: 2.8211e-06\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 4.2349e-04 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9553 - lr: 1.6927e-06\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 3.7893e-04 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9553 - lr: 1.6927e-06\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 3.8898e-04 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9553 - lr: 1.6927e-06\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 6s 44ms/step - loss: 3.7193e-04 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9553 - lr: 1.0156e-06\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 4.0403e-04 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9553 - lr: 1.0156e-06\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 6s 43ms/step - loss: 4.0071e-04 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9553 - lr: 1.0156e-06\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 3.9888e-04 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9553 - lr: 6.0936e-07\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 3.9053e-04 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9553 - lr: 6.0936e-07\n",
      "559/559 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 9s 53ms/step - loss: 0.9903 - accuracy: 0.8900 - val_loss: 0.7046 - val_accuracy: 0.5036 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.1431 - accuracy: 0.9441 - val_loss: 0.7599 - val_accuracy: 0.5036 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 0.1019 - accuracy: 0.9597 - val_loss: 0.4513 - val_accuracy: 0.7168 - lr: 0.0060\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.0949 - accuracy: 0.9647 - val_loss: 0.1354 - val_accuracy: 0.9480 - lr: 0.0060\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 0.0760 - accuracy: 0.9718 - val_loss: 0.0758 - val_accuracy: 0.9659 - lr: 0.0060\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 0.0600 - accuracy: 0.9790 - val_loss: 0.0491 - val_accuracy: 0.9749 - lr: 0.0036\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 7s 47ms/step - loss: 0.0547 - accuracy: 0.9817 - val_loss: 0.0522 - val_accuracy: 0.9803 - lr: 0.0036\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.0445 - accuracy: 0.9843 - val_loss: 0.0558 - val_accuracy: 0.9821 - lr: 0.0036\n",
      "Epoch 9/100\n",
      "115/140 [=======================>......] - ETA: 1s - loss: 0.0359 - accuracy: 0.9886"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7e99b7061359>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mX_train_CV\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mX_valid_CV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0my_train_CV\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_valid_CV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_CV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_CV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid_CV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid_CV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;31m# confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mpredicted_class\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-e841b25970bb>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n\u001b[1;32m---> 70\u001b[1;33m                             epochs=100,callbacks=callbacks_list,batch_size = 16, verbose=1)\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Implementing 10-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "k = 5 \n",
    "kf = KFold(n_splits=k, shuffle = True, random_state=3407)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "\n",
    "# result collection list\n",
    "ACC_collecton = []\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "\n",
    "for train_index , test_index in kf.split(y_train):\n",
    "    X_train_CV , X_valid_CV = X_train.iloc[train_index,:],X_train.iloc[test_index,:]\n",
    "    y_train_CV , y_valid_CV = y_train.iloc[train_index] , y_train.iloc[test_index]\n",
    "    model, model_history = build_model(X_train_CV, y_train_CV, X_valid_CV, y_valid_CV)\n",
    "    # confusion matrix \n",
    "    predicted_class= []\n",
    "    predicted_protability = model.predict(X_valid_CV,batch_size=1)\n",
    "    for i in range(predicted_protability.shape[0]):\n",
    "      index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
    "      predicted_class.append(index)\n",
    "    predicted_class = np.array(predicted_class)\n",
    "    y_true = y_valid_CV    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import math\n",
    "    # np.ravel() return a flatten 1D array\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "    ACC_collecton.append(ACC)\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    AUC = roc_auc_score(y_valid_CV, predicted_protability[:,1])\n",
    "    AUC_collecton.append(AUC)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model evaluation in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result collection list\n",
    "ACC_collecton = []\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "model, model_history = build_model(X_train, y_train, X_test , y_test)\n",
    "# confusion matrix \n",
    "predicted_class= []\n",
    "predicted_protability = model.predict(X_test,batch_size=1)\n",
    "for i in range(predicted_protability.shape[0]):\n",
    "  index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
    "  predicted_class.append(index)\n",
    "predicted_class = np.array(predicted_class)\n",
    "y_true = y_test    \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "# np.ravel() return a flatten 1D array\n",
    "TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "ACC_collecton.append(ACC)\n",
    "Sn_collecton.append(TP/(TP+FN))\n",
    "Sp_collecton.append(TN/(TN+FP))\n",
    "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "MCC_collecton.append(MCC)\n",
    "BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "from sklearn.metrics import roc_auc_score\n",
    "AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
    "AUC_collecton.append(AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
